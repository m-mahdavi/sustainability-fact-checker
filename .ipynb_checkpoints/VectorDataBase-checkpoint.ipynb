{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5AREOC49B9YO",
    "outputId": "484254c1-ab39-4f96-9c82-5da53c6a8d6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Image-SustainabiltyReport'...\n",
      "remote: Enumerating objects: 4192, done.\u001b[K\n",
      "remote: Counting objects: 100% (2586/2586), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2520/2520), done.\u001b[K\n",
      "remote: Total 4192 (delta 65), reused 2580 (delta 64), pack-reused 1606 (from 3)\u001b[K\n",
      "Receiving objects: 100% (4192/4192), 924.99 MiB | 33.06 MiB/s, done.\n",
      "Resolving deltas: 100% (116/116), done.\n",
      "Updating files: 100% (4578/4578), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ['GITHUB_TOKEN'] = \"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\"\n",
    "\n",
    "!git clone https://$GITHUB_TOKEN@github.com/amirfarahmand0/Image-SustainabiltyReport.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R66aVIJ5KS9l",
    "outputId": "65d832a6-9dbc-41d1-aa08-841ec424b23d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ftfy\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\n",
      "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
      "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: ftfy\n",
      "Successfully installed ftfy-6.3.1\n",
      "Collecting git+https://github.com/openai/CLIP.git\n",
      "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-5b90hly7\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-5b90hly7\n",
      "  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: ftfy in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (6.3.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (24.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.13.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.2)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n",
      "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: clip\n",
      "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=9634dfe618c4e123739a5c2d6be864bea75fab908d4fa1d0224f227476991aff\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-y2b91sac/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n",
      "Successfully built clip\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed clip-1.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
     ]
    }
   ],
   "source": [
    "!pip install ftfy regex tqdm\n",
    "!pip install git+https://github.com/openai/CLIP.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MgeYySuvLAPO",
    "outputId": "4734930f-35f6-4cd6-b383-ec589100716b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ayZ2ZMgqL3_8",
    "outputId": "fbdfcd31-1c10-459e-97b4-a14290ba14fe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 338M/338M [00:24<00:00, 14.3MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed google_2018_0\n",
      "Processed google_2018_1\n",
      "Processed google_2018_10\n",
      "Processed google_2018_11\n",
      "Processed google_2018_12\n",
      "Processed google_2018_13\n",
      "Processed google_2018_14\n",
      "Processed google_2018_15\n",
      "Processed google_2018_16\n",
      "Processed google_2018_17\n",
      "Processed google_2018_18\n",
      "Processed google_2018_19\n",
      "Processed google_2018_2\n",
      "Processed google_2018_20\n",
      "Processed google_2018_21\n",
      "Processed google_2018_22\n",
      "Processed google_2018_23\n",
      "Processed google_2018_24\n",
      "Processed google_2018_25\n",
      "Processed google_2018_26\n",
      "Processed google_2018_27\n",
      "Processed google_2018_28\n",
      "Processed google_2018_29\n",
      "Processed google_2018_3\n",
      "Processed google_2018_30\n",
      "Processed google_2018_31\n",
      "Processed google_2018_32\n",
      "Processed google_2018_33\n",
      "Processed google_2018_4\n",
      "Processed google_2018_5\n",
      "Processed google_2018_6\n",
      "Processed google_2018_7\n",
      "Processed google_2018_8\n",
      "Processed google_2018_9\n",
      "Processed google_2020_0\n",
      "Processed google_2020_1\n",
      "Processed google_2020_10\n",
      "Processed google_2020_11\n",
      "Processed google_2020_12\n",
      "Processed google_2020_13\n",
      "Processed google_2020_14\n",
      "Processed google_2020_15\n",
      "Processed google_2020_16\n",
      "Processed google_2020_17\n",
      "Processed google_2020_18\n",
      "Processed google_2020_19\n",
      "Processed google_2020_2\n",
      "Processed google_2020_20\n",
      "Processed google_2020_21\n",
      "Processed google_2020_22\n",
      "Processed google_2020_23\n",
      "Processed google_2020_24\n",
      "Processed google_2020_25\n",
      "Processed google_2020_26\n",
      "Processed google_2020_27\n",
      "Processed google_2020_28\n",
      "Processed google_2020_29\n",
      "Processed google_2020_3\n",
      "Processed google_2020_30\n",
      "Processed google_2020_31\n",
      "Processed google_2020_32\n",
      "Processed google_2020_33\n",
      "Processed google_2020_34\n",
      "Processed google_2020_35\n",
      "Processed google_2020_36\n",
      "Processed google_2020_4\n",
      "Processed google_2020_5\n",
      "Processed google_2020_6\n",
      "Processed google_2020_7\n",
      "Processed google_2020_8\n",
      "Processed google_2020_9\n",
      "Processed google_2019_0\n",
      "Processed google_2019_1\n",
      "Processed google_2019_10\n",
      "Processed google_2019_11\n",
      "Processed google_2019_12\n",
      "Processed google_2019_13\n",
      "Processed google_2019_14\n",
      "Processed google_2019_15\n",
      "Processed google_2019_16\n",
      "Processed google_2019_17\n",
      "Processed google_2019_18\n",
      "Processed google_2019_19\n",
      "Processed google_2019_2\n",
      "Processed google_2019_20\n",
      "Processed google_2019_21\n",
      "Processed google_2019_22\n",
      "Processed google_2019_23\n",
      "Processed google_2019_24\n",
      "Processed google_2019_25\n",
      "Processed google_2019_26\n",
      "Processed google_2019_3\n",
      "Processed google_2019_4\n",
      "Processed google_2019_5\n",
      "Processed google_2019_6\n",
      "Processed google_2019_7\n",
      "Processed google_2019_8\n",
      "Processed google_2019_9\n",
      "Processed google_2024_0\n",
      "Processed google_2024_1\n",
      "Processed google_2024_10\n",
      "Processed google_2024_100\n",
      "Processed google_2024_101\n",
      "Processed google_2024_102\n",
      "Processed google_2024_103\n",
      "Processed google_2024_104\n",
      "Processed google_2024_105\n",
      "Processed google_2024_106\n",
      "Processed google_2024_107\n",
      "Processed google_2024_108\n",
      "Processed google_2024_109\n",
      "Processed google_2024_11\n",
      "Processed google_2024_110\n",
      "Processed google_2024_111\n",
      "Processed google_2024_112\n",
      "Processed google_2024_113\n",
      "Processed google_2024_114\n",
      "Processed google_2024_115\n",
      "Processed google_2024_116\n",
      "Processed google_2024_117\n",
      "Processed google_2024_118\n",
      "Processed google_2024_119\n",
      "Processed google_2024_12\n",
      "Processed google_2024_120\n",
      "Processed google_2024_121\n",
      "Processed google_2024_122\n",
      "Processed google_2024_123\n",
      "Processed google_2024_124\n",
      "Processed google_2024_125\n",
      "Processed google_2024_126\n",
      "Processed google_2024_127\n",
      "Processed google_2024_128\n",
      "Processed google_2024_129\n",
      "Processed google_2024_13\n",
      "Processed google_2024_130\n",
      "Processed google_2024_131\n",
      "Processed google_2024_132\n",
      "Processed google_2024_133\n",
      "Processed google_2024_134\n",
      "Processed google_2024_135\n",
      "Processed google_2024_136\n",
      "Processed google_2024_137\n",
      "Processed google_2024_138\n",
      "Processed google_2024_139\n",
      "Processed google_2024_14\n",
      "Processed google_2024_140\n",
      "Processed google_2024_141\n",
      "Processed google_2024_142\n",
      "Processed google_2024_143\n",
      "Processed google_2024_144\n",
      "Processed google_2024_145\n",
      "Processed google_2024_146\n",
      "Processed google_2024_147\n",
      "Processed google_2024_148\n",
      "Processed google_2024_149\n",
      "Processed google_2024_15\n",
      "Processed google_2024_150\n",
      "Processed google_2024_151\n",
      "Processed google_2024_152\n",
      "Processed google_2024_153\n",
      "Processed google_2024_154\n",
      "Processed google_2024_155\n",
      "Processed google_2024_156\n",
      "Processed google_2024_157\n",
      "Processed google_2024_158\n",
      "Processed google_2024_159\n",
      "Processed google_2024_16\n",
      "Processed google_2024_160\n",
      "Processed google_2024_161\n",
      "Processed google_2024_162\n",
      "Processed google_2024_163\n",
      "Processed google_2024_164\n",
      "Processed google_2024_165\n",
      "Processed google_2024_166\n",
      "Processed google_2024_167\n",
      "Processed google_2024_168\n",
      "Processed google_2024_169\n",
      "Processed google_2024_17\n",
      "Processed google_2024_170\n",
      "Processed google_2024_171\n",
      "Processed google_2024_172\n",
      "Processed google_2024_173\n",
      "Processed google_2024_174\n",
      "Processed google_2024_175\n",
      "Processed google_2024_176\n",
      "Processed google_2024_177\n",
      "Processed google_2024_178\n",
      "Processed google_2024_179\n",
      "Processed google_2024_18\n",
      "Processed google_2024_180\n",
      "Processed google_2024_181\n",
      "Processed google_2024_182\n",
      "Processed google_2024_183\n",
      "Processed google_2024_184\n",
      "Processed google_2024_185\n",
      "Processed google_2024_186\n",
      "Processed google_2024_187\n",
      "Processed google_2024_188\n",
      "Processed google_2024_189\n",
      "Processed google_2024_19\n",
      "Processed google_2024_190\n",
      "Processed google_2024_191\n",
      "Processed google_2024_192\n",
      "Processed google_2024_193\n",
      "Processed google_2024_194\n",
      "Processed google_2024_195\n",
      "Processed google_2024_196\n",
      "Processed google_2024_197\n",
      "Processed google_2024_198\n",
      "Processed google_2024_199\n",
      "Processed google_2024_2\n",
      "Processed google_2024_20\n",
      "Processed google_2024_200\n",
      "Processed google_2024_201\n",
      "Processed google_2024_21\n",
      "Processed google_2024_22\n",
      "Processed google_2024_23\n",
      "Processed google_2024_24\n",
      "Processed google_2024_25\n",
      "Processed google_2024_26\n",
      "Processed google_2024_27\n",
      "Processed google_2024_28\n",
      "Processed google_2024_29\n",
      "Processed google_2024_3\n",
      "Processed google_2024_30\n",
      "Processed google_2024_31\n",
      "Processed google_2024_32\n",
      "Processed google_2024_33\n",
      "Processed google_2024_34\n",
      "Processed google_2024_35\n",
      "Processed google_2024_36\n",
      "Processed google_2024_37\n",
      "Processed google_2024_38\n",
      "Processed google_2024_39\n",
      "Processed google_2024_4\n",
      "Processed google_2024_40\n",
      "Processed google_2024_41\n",
      "Processed google_2024_42\n",
      "Processed google_2024_43\n",
      "Processed google_2024_44\n",
      "Processed google_2024_45\n",
      "Processed google_2024_46\n",
      "Processed google_2024_47\n",
      "Processed google_2024_48\n",
      "Processed google_2024_49\n",
      "Processed google_2024_5\n",
      "Processed google_2024_50\n",
      "Processed google_2024_51\n",
      "Processed google_2024_52\n",
      "Processed google_2024_53\n",
      "Processed google_2024_54\n",
      "Processed google_2024_55\n",
      "Processed google_2024_56\n",
      "Processed google_2024_57\n",
      "Processed google_2024_58\n",
      "Processed google_2024_59\n",
      "Processed google_2024_6\n",
      "Processed google_2024_60\n",
      "Processed google_2024_61\n",
      "Processed google_2024_62\n",
      "Processed google_2024_63\n",
      "Processed google_2024_64\n",
      "Processed google_2024_65\n",
      "Processed google_2024_66\n",
      "Processed google_2024_67\n",
      "Processed google_2024_68\n",
      "Processed google_2024_69\n",
      "Processed google_2024_7\n",
      "Processed google_2024_70\n",
      "Processed google_2024_71\n",
      "Processed google_2024_72\n",
      "Processed google_2024_73\n",
      "Processed google_2024_74\n",
      "Processed google_2024_75\n",
      "Processed google_2024_76\n",
      "Processed google_2024_77\n",
      "Processed google_2024_78\n",
      "Processed google_2024_79\n",
      "Processed google_2024_8\n",
      "Processed google_2024_80\n",
      "Processed google_2024_81\n",
      "Processed google_2024_82\n",
      "Processed google_2024_83\n",
      "Processed google_2024_84\n",
      "Processed google_2024_85\n",
      "Processed google_2024_86\n",
      "Processed google_2024_87\n",
      "Processed google_2024_88\n",
      "Processed google_2024_89\n",
      "Processed google_2024_9\n",
      "Processed google_2024_90\n",
      "Processed google_2024_91\n",
      "Processed google_2024_92\n",
      "Processed google_2024_93\n",
      "Processed google_2024_94\n",
      "Processed google_2024_95\n",
      "Processed google_2024_96\n",
      "Processed google_2024_97\n",
      "Processed google_2024_98\n",
      "Processed google_2024_99\n",
      "Processed google_2022_0\n",
      "Processed google_2023_0\n",
      "Processed google_2023_1\n",
      "Processed google_2023_10\n",
      "Processed google_2023_11\n",
      "Processed google_2023_12\n",
      "Processed google_2023_13\n",
      "Processed google_2023_14\n",
      "Processed google_2023_15\n",
      "Processed google_2023_16\n",
      "Processed google_2023_17\n",
      "Processed google_2023_18\n",
      "Processed google_2023_19\n",
      "Processed google_2023_2\n",
      "Processed google_2023_20\n",
      "Processed google_2023_21\n",
      "Processed google_2023_22\n",
      "Processed google_2023_23\n",
      "Processed google_2023_24\n",
      "Processed google_2023_25\n",
      "Processed google_2023_26\n",
      "Processed google_2023_27\n",
      "Processed google_2023_28\n",
      "Processed google_2023_29\n",
      "Processed google_2023_3\n",
      "Processed google_2023_30\n",
      "Processed google_2023_31\n",
      "Processed google_2023_32\n",
      "Processed google_2023_33\n",
      "Processed google_2023_34\n",
      "Processed google_2023_35\n",
      "Processed google_2023_36\n",
      "Processed google_2023_37\n",
      "Processed google_2023_38\n",
      "Processed google_2023_39\n",
      "Processed google_2023_4\n",
      "Processed google_2023_40\n",
      "Processed google_2023_41\n",
      "Processed google_2023_42\n",
      "Processed google_2023_43\n",
      "Processed google_2023_44\n",
      "Processed google_2023_45\n",
      "Processed google_2023_46\n",
      "Processed google_2023_47\n",
      "Processed google_2023_48\n",
      "Processed google_2023_49\n",
      "Processed google_2023_5\n",
      "Processed google_2023_50\n",
      "Processed google_2023_51\n",
      "Processed google_2023_52\n",
      "Processed google_2023_53\n",
      "Processed google_2023_54\n",
      "Processed google_2023_55\n",
      "Processed google_2023_56\n",
      "Processed google_2023_57\n",
      "Processed google_2023_58\n",
      "Processed google_2023_59\n",
      "Processed google_2023_6\n",
      "Processed google_2023_60\n",
      "Processed google_2023_61\n",
      "Processed google_2023_62\n",
      "Processed google_2023_63\n",
      "Processed google_2023_64\n",
      "Processed google_2023_65\n",
      "Processed google_2023_66\n",
      "Processed google_2023_67\n",
      "Processed google_2023_68\n",
      "Processed google_2023_69\n",
      "Processed google_2023_7\n",
      "Processed google_2023_70\n",
      "Processed google_2023_71\n",
      "Processed google_2023_72\n",
      "Processed google_2023_73\n",
      "Processed google_2023_74\n",
      "Processed google_2023_75\n",
      "Processed google_2023_76\n",
      "Processed google_2023_77\n",
      "Processed google_2023_78\n",
      "Processed google_2023_79\n",
      "Processed google_2023_8\n",
      "Processed google_2023_80\n",
      "Processed google_2023_81\n",
      "Processed google_2023_82\n",
      "Processed google_2023_83\n",
      "Processed google_2023_84\n",
      "Processed google_2023_85\n",
      "Processed google_2023_86\n",
      "Processed google_2023_87\n",
      "Processed google_2023_88\n",
      "Processed google_2023_89\n",
      "Processed google_2023_9\n",
      "Processed google_2023_90\n",
      "Processed google_2023_91\n",
      "Processed google_2023_92\n",
      "Processed google_2023_93\n",
      "Processed google_2021_0\n",
      "Done. Database saved with 396 records in embeddings_database.json.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import clip\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model.eval()\n",
    "base_folder = os.path.join(\"Image-SustainabiltyReport\", \"images\", \"google\")\n",
    "records = []\n",
    "\n",
    "for folder in os.listdir(base_folder):\n",
    "    folder_path = os.path.join(base_folder, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        try:\n",
    "            year = int(folder.split(\"_\")[1])\n",
    "        except (IndexError, ValueError):\n",
    "            print(f\"Skipping folder with unexpected name format: {folder}\")\n",
    "            continue\n",
    "\n",
    "        for file_name in sorted(os.listdir(folder_path)):\n",
    "            if not file_name.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\", \".tiff\")):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            try:\n",
    "                image = Image.open(file_path).convert(\"RGB\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error opening image {file_path}: {e}\")\n",
    "                continue\n",
    "\n",
    "            image_input = preprocess(image).unsqueeze(0).to(device)\n",
    "            with torch.no_grad():\n",
    "                embedding = model.encode_image(image_input)\n",
    "            # Normalize the embedding vector\n",
    "            embedding = embedding / embedding.norm(dim=-1, keepdim=True)\n",
    "            # Convert to a list so it can be JSON serialized\n",
    "            embedding = embedding.cpu().numpy().tolist()[0]\n",
    "            record_id = f\"{folder}_{os.path.splitext(file_name)[0]}\"\n",
    "            record = {\n",
    "                \"id\": record_id,\n",
    "                \"year\": year,\n",
    "                \"embedding\": embedding\n",
    "            }\n",
    "            records.append(record)\n",
    "            print(f\"Processed {record_id}\")\n",
    "\n",
    "output_file = \"embeddings_database.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(records, f, indent=2)\n",
    "\n",
    "print(f\"Done. Database saved with {len(records)} records in {output_file}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H_veAa_dPHzl",
    "outputId": "cee3303f-359a-4b59-cfc7-823e52293209"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated 396 records. New file saved as embeddings_database_updated.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "input_file = \"embeddings_database.json\"\n",
    "with open(input_file, \"r\") as f:\n",
    "    records = json.load(f)\n",
    "\n",
    "for record in records:\n",
    "    record[\"type\"] = \"image\"\n",
    "output_file = \"embeddings_database_updated.json\"\n",
    "with open(output_file, \"w\") as f:\n",
    "    json.dump(records, f, indent=2)\n",
    "\n",
    "print(f\"Updated {len(records)} records. New file saved as {output_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
